command:
- ${interpreter}
- ${program}
- --do_train
- --do_eval
- ${args}
method: bayes
metric:
  goal: maximize
  name: best_dev_avg_weak_hits@1
name: FreebaseQA
parameters:
  add_dist_feature:
    value: 1
  add_inv_edges_to_edge_index:
    value: 1
  data_dir:
    value: /mnt/nfs/work1/mccallum/rajarshi/cbr-weak-supervision/FreebaseQA/
  data_file_suffix:
    value: roberta-base_mean_pool_masked_cbr_subgraph_k=25
  dataset_name:
    value: freebaseqa
  dist_metric:
    value: cosine
  eval_batch_size:
    value: 1
  eval_steps:
    value: 100
  gradient_accumulation_steps:
    values:
    - 4
    - 8
  learning_rate:
    distribution: uniform
    max: 0.01
    min: 0.0001
  logging_steps:
    value: 10
  loss_metric:
    value: txent
  max_grad_norm:
    value: 1
  num_gcn_layers:
    value: 3
  num_neighbors_eval:
    values:
    - 5
    - 7
    - 10
  num_neighbors_train:
    values:
    - 5
    - 7
    - 10
  num_train_epochs:
    value: 30
  output_dir:
    value: /mnt/nfs/work1/mccallum/rajarshi/cbr-weak-supervision/expts/freebaseqa/
  save_steps:
    value: 80
  save_total_limit:
    value: 1
  task:
    value: pt_match
  temperature:
    distribution: uniform
    max: 0.1
    min: 0.001
  train_batch_size:
    value: 1
  transform_input:
    value: 1
  use_fast_rgcn:
    value: 1
  use_wandb:
    value: 1
program: runner.py
project: cbr-weak-supervision