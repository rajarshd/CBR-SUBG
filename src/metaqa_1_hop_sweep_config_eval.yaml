command:
  - ${interpreter}
  - ${program}
  - --do_predict
  - ${args}
method: bayes
metric:
  goal: maximize
  name: best_dev_avg_weak_hits@1
name: MetaQA-1hop-eval
parameters:
  add_dist_feature:
    value: 1
  add_inv_edges_to_edge_index:
    value: 1
  data_dir:
    value: /mnt/nfs/work1/mccallum/rajarshi/cbr-weak-supervision/MetaQA-synthetic/1-hop/
  dataset_name:
    value: metaqa
  eval_batch_size:
    value: 1
  eval_steps:
    value: 1024
  gradient_accumulation_steps:
    value: 8
  learning_rate:
    value: 0.0009820476602030797
  logging_steps:
    value: 10
  loss_metric:
    value: txent
  max_grad_norm:
    value: 1
  model_ckpt_path:
    value: /mnt/nfs/work1/mccallum/rajarshi/cbr-weak-supervision/expts/metaqa_1hop/out-220126_234053_eb2c3a47/pytorch_model.bin
  num_gcn_layers:
    value: 3
  num_neighbors_eval:
    values:
      - 10
      - 12
      - 15
      - 20
      - 25
  num_neighbors_train:
    value: 7
  num_train_epochs:
    value: 5
  output_dir:
    value: /mnt/nfs/work1/mccallum/rajarshi/cbr-weak-supervision/expts/metaqa_1hop/
  save_steps:
    value: 80
  save_total_limit:
    value: 1
  task:
    value: pt_match
  train_batch_size:
    value: 1
  temperature:
    value: 0.08380032551264051
  transform_input:
    value: 1
  use_fast_rgcn:
    value: 1
  use_wandb:
    value: 1
program: runner.py
project: cbr-weak-supervision